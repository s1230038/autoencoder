{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoencoderForThesis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1230038/autoencoder/blob/master/AutoencoderForThesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "42k_7hqZp7yx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm *txt *h5 *png *zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5NaL7in5Jc1",
        "colab_type": "code",
        "outputId": "5fcc8a4a-0a8a-4a01-fdf6-f1909b7012e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1854
        }
      },
      "cell_type": "code",
      "source": [
        "# Simple Autoencoder using Other Loss Function\n",
        "# Original: https://elix-tech.github.io/ja/2016/07/17/autoencoder.html\n",
        "# https://colab.research.google.com/drive/1Z_d8APkMUDwXDQIg3OI7E13vH8IZhusM?authuser=1#scrollTo=WmBfOis_mWCH\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import losses\n",
        "from tensorflow.python import debug as tf_debug\n",
        "from itertools import product\n",
        "from google.colab import files\n",
        "from keras import optimizers\n",
        "\n",
        "# imititing mean_squared_error():\n",
        "# Èùí„Ç§„É´„Ç´ P.57„Åß„ÅØ‰∫å‰πóË™§Â∑Æ„ÅÆÁ∑èÂíå„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Çã„Åå„ÄÅ„Åì„Çå„ÇíKeras„ÅßÂÆüË£Ö„Åô„ÇãÂ†¥Âêà„ÅØÂπ≥Âùá‰∫å‰πóË™§Â∑ÆÔºàmean_squared_error)\n",
        "# „Çíloss „Å´Ê∏°„ÅôÂøÖË¶Å„Åå„ÅÇ„Çã„ÄÇ„Å™„Åú„Å™„Çâ„ÄÅKeras„ÅØ„Éü„Éã„Éê„ÉÉ„ÉÅ„Åßfit()„ÇíË®àÁÆó„Åô„Çã„Åã„Çâ„Åß„ÅÇ„Çã„ÄÇÈùí„Ç§„É´„Ç´ P.27ÂèÇÁÖß„ÄÇ\n",
        "# ùíô ÃÇ_ùëõ :y_pred,  ùíô_ùëõ : y_true, because x_n is training data which means label.\n",
        "def i_divergence1(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean(y_pred * K.log(y_pred / y_true) - y_pred + y_true, axis=-1)\n",
        "\n",
        "def i_divergence2(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean(y_true * K.log(y_true / y_pred) - y_true + y_pred, axis=-1)\n",
        "\n",
        "def is_divergence1(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean( (y_pred / y_true) - K.log(y_pred / y_true) - 1, axis=-1)\n",
        "\n",
        "def is_divergence2(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean( (y_true / y_pred) - K.log(y_true / y_pred) - 1, axis=-1)\n",
        "\n",
        "# https://qiita.com/hiroyuki827/items/213146d551a6e2227810\n",
        "def plot_history_loss(np_loss, np_vloss, name):\n",
        "    # Plot the loss in the history\n",
        "    fig, axL = plt.subplots(figsize=(8,6), dpi=500) # „Ç∞„É©„Éï„ÅÆË°®Á§∫Ê∫ñÂÇô\n",
        "    axL.plot(np_loss, label=\"loss for training\")\n",
        "    axL.plot(np_vloss, label=\"loss for validation\")\n",
        "    axL.set_title('model loss: ' + name)\n",
        "    axL.set_xlabel('epoch')\n",
        "    axL.set_ylabel('loss')\n",
        "    axL.legend(loc='upper right')\n",
        "    return fig\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "# Download MNIST and standardize, learning\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# we will restrict domain of definition of the input data to the below expression with normalization of the input.\n",
        "x_train = x_train.astype('float32') / 255. # ÁîªÂÉè„Éá„Éº„Çø„ÅØ0„Åã„Çâ1„ÅÆÂÆüÊï∞ÂÄ§„ÇíÂèñ„Çã„Çà„ÅÜ„Å´Ë¶èÊ†ºÂåñ\n",
        "x_test = x_test.astype('float32') / 255.   # {0,1}„ÅÆ‰∫åÂÄ§„Åß„ÅØ„Å™„ÅèÂÆüÊï∞ÂÄ§„Åß„ÅÇ„Çã„Åì„Å®„Å´Ê≥®ÊÑè\n",
        "# x_train„ÅØ (60000, 28, 28) „Å®„ÅÑ„ÅÜÂΩ¢„Çí„Åó„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅ784Ê¨°ÂÖÉ„ÅÆÂÖ•Âäõ„Å´„Å™„Çã„Çà„ÅÜ„Å´ (60000, 784) „Å´Â§âÂΩ¢\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "# hyper parameter combination\n",
        "'''\n",
        "lossfs = [losses.mean_squared_error, i_divergence1, i_divergence2, is_divergence1, is_divergence2]\n",
        "acts = [\"relu\", \"sigmoid\"]\n",
        "opzs = [\"SGD\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adam\", \"Adamax\", \"Nadam\"]\n",
        "'''\n",
        "lossfs = [is_divergence2]\n",
        "acts   = [\"relu\"]\n",
        "list1  = np.arange(0.7, 1.2, 0.1)\n",
        "list2  = np.arange(0.90, 1.0, 0.01)\n",
        "list3  = [0.0, 0.01]\n",
        "# ------------------------------------------\n",
        "for loss, dact, op1, op2, op3 in product(lossfs, acts, list1, list2, list3):\n",
        "  optimizer = optimizers.Adadelta(lr=op1, rho=op2, decay=op3 )\n",
        "  file_prefix = (loss.__name__ + '_' + dact + '_' + optimizer.__class__.__name__ + '_'  +\n",
        "                str(op1) + '_' + str(op2) + '_' + str(op3) + '_'  )\n",
        "  print(\"start: \" + file_prefix )\n",
        "  encoding_dim = 32\n",
        "  input_img = Input(shape=(784,))\n",
        "  encoded = Dense(encoding_dim, activation='relu')(input_img) \n",
        "  decoded = Dense(784, activation=dact)(encoded)\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded) # https://medium.com/@zhuixiyou/userwarning-update-your-model-call-to-the-keras-2-api-8a6a5955daac\n",
        "  # autoencoder„Åß„ÅØ„ÄÅÊïôÂ∏´„Éá„Éº„Çø„Å´„É©„Éô„É´„Çí‰Ωø„Çè„Å™„ÅÑ„Åü„ÇÅaccuracy„ÅÆË®àÁÆó„ÅØ‰∏çË¶Å„ÄÇ\n",
        "  autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "  # ------------------------------------------\n",
        "  fit = autoencoder.fit(x_train, x_train,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=256,\n",
        "                  shuffle=True,\n",
        "                  verbose=0,\n",
        "                  validation_data=(x_test, x_test))\n",
        "\n",
        "  # loss„ÅÆCSV„Éï„Ç°„Ç§„É´„ÅÆ‰øùÂ≠ò\n",
        "  loss_his = fit.history['loss']\n",
        "  vloss_his = fit.history['val_loss']\n",
        "  np_loss = np.array(loss_his)\n",
        "  np_vloss = np.array(vloss_his)\n",
        "  np.savetxt(file_prefix + \"loss_history.txt\",     np_loss,  delimiter=\",\")\n",
        "  np.savetxt(file_prefix + \"val_loss_history.txt\", np_vloss, delimiter=\",\")\n",
        "  \n",
        "  # „Ç∞„É©„Éï„ÅÆ‰øùÂ≠ò\n",
        "  fig = plot_history_loss(np_loss, np_vloss, loss.__name__)\n",
        "  fig.savefig(file_prefix + \"loss_history.png\")\n",
        "  plt.close()\n",
        "  \n",
        "  # Â≠¶Áøí„Åó„ÅüÈáç„Åø„Çí‰øùÂ≠ò\n",
        "  autoencoder.save_weights(file_prefix + 'autoencoder.h5')\n",
        "  \n",
        "  autoencoder.reset_states()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start: is_divergence2_relu_Adadelta_0.7_0.9_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.91_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.91_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.92_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.92_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.93_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.93_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.01_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.0_\n",
            "start: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.01_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVwTIp0j2BUE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------\n",
        "for loss, dact, op1, op2, op3, op4 in product(lossfs, acts, list1, list2, list3, list4):\n",
        "  optimizer = optimizers.Adamax(lr=op1, beta_1=op2, beta_2=op3, decay=op4)\n",
        "  file_prefix = (loss.__name__ + '_' + dact + '_' + optimizer.__class__.__name__ + '_'  +\n",
        "                str(op1) + '_' + str(op2) + '_' + str(op3) + '_' + str(op4) + '_' )\n",
        "  print(\"start: \" + file_prefix )\n",
        "  encoding_dim = 32\n",
        "  input_img = Input(shape=(784,))\n",
        "  encoded = Dense(encoding_dim, activation='relu')(input_img) \n",
        "  decoded = Dense(784, activation=dact)(encoded)\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded) # https://medium.com/@zhuixiyou/userwarning-update-your-model-call-to-the-keras-2-api-8a6a5955daac\n",
        "  # autoencoder„Åß„ÅØ„ÄÅÊïôÂ∏´„Éá„Éº„Çø„Å´„É©„Éô„É´„Çí‰Ωø„Çè„Å™„ÅÑ„Åü„ÇÅaccuracy„ÅÆË®àÁÆó„ÅØ‰∏çË¶Å„ÄÇ\n",
        "  autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "  # ------------------------------------------\n",
        "  # ‰øùÂ≠ò„Åó„ÅüÈáç„Åø„ÇíË™≠„ÅøËæº„Åø\n",
        "  autoencoder.load_weights(file_prefix + 'autoencoder.h5')\n",
        "  decoded_imgs = autoencoder.predict(x_test)\n",
        "  # 0-9„ÇíË°®Á§∫„Åô„Çã\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  label = 0\n",
        "  for i in range(1000):\n",
        "      if label > 10:\n",
        "          break\n",
        "      elif label != y_test[i]:\n",
        "          continue\n",
        "      # „Ç™„É™„Ç∏„Éä„É´„ÅÆ„ÉÜ„Çπ„ÉàÁîªÂÉè„ÇíË°®Á§∫\n",
        "      plt.imshow(x_test[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      plt.savefig(str(i) + '_x_test_numbers.png')\n",
        "\n",
        "      # Â§âÊèõ„Åï„Çå„ÅüÁîªÂÉè„ÇíË°®Á§∫\n",
        "      plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      plt.savefig(file_prefix + str(i) + '_decoded_numbers.png')\n",
        "      \n",
        "      label+=1\n",
        "  #  plt.show() #show()„Åô„Çã„Å®„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò„Åß„Åç„Å™„ÅÑ„Åì„Å®„Å´Ê≥®ÊÑè„ÄÇ\n",
        "  autoencoder.reset_states()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LK23VO2zjflG",
        "colab_type": "code",
        "outputId": "3e23e3e9-c340-4962-a0c6-91b95fb672c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7310
        }
      },
      "cell_type": "code",
      "source": [
        "# ‰øùÂ≠ò„Åó„ÅüÈáç„Åø„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n",
        "from google.colab import files\n",
        "!zip -r h5.zip *.h5\n",
        "!zip -r png.zip *.png\n",
        "!zip -r txt.zip *.txt\n",
        "files.download('h5.zip')\n",
        "files.download('png.zip')\n",
        "files.download('txt.zip')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.01_autoencoder.h5 (deflated 14%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.0_autoencoder.h5 (deflated 13%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.01_loss_history.png (deflated 22%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.0_loss_history.png (deflated 28%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.01_loss_history.png (deflated 22%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.01_loss_history.png (deflated 22%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.01_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.0_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.01_loss_history.png (deflated 22%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.01_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.01_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.01_loss_history.png (deflated 22%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.01_loss_history.png (deflated 22%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.0_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.01_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.01_loss_history.png (deflated 22%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.0_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.01_loss_history.png (deflated 23%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.0_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.01_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.0_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.01_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.01_loss_history.png (deflated 24%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.01_loss_history.png (deflated 28%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.0_loss_history.png (deflated 26%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.01_loss_history.png (deflated 27%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.01_loss_history.png (deflated 28%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.0_loss_history.png (deflated 25%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.0_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9_0.0_val_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.0_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.91_0.0_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.92_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.93_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9400000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.0_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9500000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9600000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9700000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9800000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.01_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.0_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7_0.9900000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.0_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.91_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.01_val_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.92_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.93_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9400000000000001_0.0_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9500000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9600000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9700000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9800000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.01_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.01_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.7999999999999999_0.9900000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.91_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.92_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.93_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9400000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9500000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9600000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9700000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9800000000000001_0.0_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.01_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.01_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.8999999999999999_0.9900000000000001_0.0_val_loss_history.txt (deflated 66%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.0_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.91_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.92_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.93_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9400000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.0_loss_history.txt (deflated 59%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9500000000000001_0.0_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9600000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9700000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.01_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.0_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9800000000000001_0.0_val_loss_history.txt (deflated 66%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_0.9999999999999999_0.9900000000000001_0.0_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.01_loss_history.txt (deflated 59%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.0_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9_0.0_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.01_val_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.91_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.92_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.01_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.93_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.01_loss_history.txt (deflated 60%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.0_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9400000000000001_0.0_val_loss_history.txt (deflated 66%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9500000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.01_loss_history.txt (deflated 61%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.01_val_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.0_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9600000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.01_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.01_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9700000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.01_loss_history.txt (deflated 62%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.01_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.0_loss_history.txt (deflated 63%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9800000000000001_0.0_val_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.01_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.01_val_loss_history.txt (deflated 65%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.0_loss_history.txt (deflated 64%)\n",
            "  adding: is_divergence2_relu_Adadelta_1.0999999999999999_0.9900000000000001_0.0_val_loss_history.txt (deflated 64%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_j9zZq4yb4Sc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/image/ssim\n",
        "'''\n",
        "This function is based on the standard SSIM implementation from:\n",
        "Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004).\n",
        "Image quality assessment: from error visibility to structural similarity. \n",
        "IEEE transactions on image processing\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}