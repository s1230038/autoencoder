{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoencoderForThesis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1230038/autoencoder/blob/master/AutoencoderForThesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "42k_7hqZp7yx",
        "colab_type": "code",
        "outputId": "08d1baa3-b6d1-4bd7-a280-667d60a9f707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "rm *txt *h5 *png *zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*txt': No such file or directory\n",
            "rm: cannot remove '*h5': No such file or directory\n",
            "rm: cannot remove '*png': No such file or directory\n",
            "rm: cannot remove '*zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d5NaL7in5Jc1",
        "colab_type": "code",
        "outputId": "1cb3ab10-02e8-4dac-ab49-6632034b0c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "# Simple Autoencoder using Other Loss Function\n",
        "# Original: https://elix-tech.github.io/ja/2016/07/17/autoencoder.html\n",
        "# https://colab.research.google.com/drive/1Z_d8APkMUDwXDQIg3OI7E13vH8IZhusM?authuser=1#scrollTo=WmBfOis_mWCH\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import losses\n",
        "from tensorflow.python import debug as tf_debug\n",
        "from itertools import product\n",
        "from google.colab import files\n",
        "from keras import optimizers\n",
        "from keras import constraints as cst\n",
        "\n",
        "# imititing mean_squared_error():\n",
        "# 青イルカ P.57では二乗誤差の総和を使用しているが、これをKerasで実装する場合は平均二乗誤差（mean_squared_error)\n",
        "# をloss に渡す必要がある。なぜなら、Kerasはミニバッチでfit()を計算するからである。青イルカ P.27参照。\n",
        "# 𝒙 ̂_𝑛 :y_pred,  𝒙_𝑛 : y_true, because x_n is training data which means label.\n",
        "def i_divergence1(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean(y_pred * K.log(y_pred / y_true) - y_pred + y_true, axis=-1)\n",
        "\n",
        "def i_divergence2(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean(y_true * K.log(y_true / y_pred) - y_true + y_pred, axis=-1)\n",
        "\n",
        "def is_divergence1(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean( (y_pred / y_true) - K.log(y_pred / y_true) - 1, axis=-1)\n",
        "\n",
        "def is_divergence2(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean( (y_true / y_pred) - K.log(y_true / y_pred) - 1, axis=-1)\n",
        "\n",
        "# https://qiita.com/hiroyuki827/items/213146d551a6e2227810\n",
        "def plot_history_loss(np_loss, np_vloss, name):\n",
        "    # Plot the loss in the history\n",
        "    fig, axL = plt.subplots(figsize=(8,6), dpi=500) # グラフの表示準備\n",
        "    axL.plot(np_loss, label=\"loss for training\")\n",
        "    axL.plot(np_vloss, label=\"loss for validation\")\n",
        "    axL.set_title('model loss: ' + name)\n",
        "    axL.set_xlabel('epoch')\n",
        "    axL.set_ylabel('loss')\n",
        "    axL.legend(loc='upper right')\n",
        "    return fig\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "# Download MNIST and standardize, learning\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# we will restrict domain of definition of the input data to the below expression with normalization of the input.\n",
        "x_train = x_train.astype('float32') / 255. # 画像データは0から1の実数値を取るように規格化\n",
        "x_test = x_test.astype('float32') / 255.   # {0,1}の二値ではなく実数値であることに注意\n",
        "# x_trainは (60000, 28, 28) という形をしていますが、784次元の入力になるように (60000, 784) に変形\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "# hyper parameter combination\n",
        "'''\n",
        "lossfs = [losses.mean_squared_error, i_divergence1, i_divergence2, is_divergence1, is_divergence2]\n",
        "acts = [\"relu\", \"sigmoid\"]\n",
        "opzs = [\"SGD\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adam\", \"Adamax\", \"Nadam\"]\n",
        "'''\n",
        "lossfs = [losses.mean_squared_error, i_divergence1, i_divergence2]\n",
        "acts = [\"relu\", \"sigmoid\"]\n",
        "opzs = [\"SGD\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adam\", \"Adamax\", \"Nadam\"]\n",
        "# ------------------------------------------\n",
        "for loss, dact, optimizer in product(lossfs, acts, opzs):\n",
        "  file_prefix = (loss.__name__ + '_' + dact + '_' + optimizer + '_' )\n",
        "  print(\"start: \" + file_prefix )\n",
        "  encoding_dim = 32\n",
        "  input_img = Input(shape=(784,))\n",
        "  encoded = Dense(encoding_dim, activation='relu', \n",
        "                  kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(input_img) \n",
        "  decoded = Dense(784, activation=dact, kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(encoded)\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded) # https://medium.com/@zhuixiyou/userwarning-update-your-model-call-to-the-keras-2-api-8a6a5955daac\n",
        "  # autoencoderでは、教師データにラベルを使わないためaccuracyの計算は不要。\n",
        "  autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "  # ------------------------------------------\n",
        "  fit = autoencoder.fit(x_train, x_train,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=256,\n",
        "                  shuffle=True,\n",
        "                  verbose=0,\n",
        "                  validation_data=(x_test, x_test))\n",
        "\n",
        "  # lossのCSVファイルの保存\n",
        "  loss_his = fit.history['loss']\n",
        "  vloss_his = fit.history['val_loss']\n",
        "  np_loss = np.array(loss_his)\n",
        "  np_vloss = np.array(vloss_his)\n",
        "  np.savetxt(file_prefix + \"loss_history.txt\",     np_loss,  delimiter=\",\")\n",
        "  np.savetxt(file_prefix + \"val_loss_history.txt\", np_vloss, delimiter=\",\")\n",
        "  \n",
        "  # グラフの保存\n",
        "  fig = plot_history_loss(np_loss, np_vloss, loss.__name__)\n",
        "  fig.savefig(file_prefix + \"loss_history.png\")\n",
        "  plt.close()\n",
        "  \n",
        "  # 学習した重みを保存\n",
        "  autoencoder.save_weights(file_prefix + 'autoencoder.h5')\n",
        "  \n",
        "  autoencoder.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "start: mean_squared_error_relu_SGD_\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "start: mean_squared_error_relu_RMSprop_\n",
            "start: mean_squared_error_relu_Adagrad_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVwTIp0j2BUE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------\n",
        "for loss, dact, optimizer in product(lossfs, acts, opzs):\n",
        "  file_prefix = (loss.__name__ + '_' + dact + '_' + optimizer + '_' )\n",
        "  print(\"start: \" + file_prefix )\n",
        "  encoding_dim = 32\n",
        "  input_img = Input(shape=(784,))\n",
        "  encoded = Dense(encoding_dim, activation='relu', \n",
        "                  kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(input_img) \n",
        "  decoded = Dense(784, activation=dact, kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(encoded)\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded) # https://medium.com/@zhuixiyou/userwarning-update-your-model-call-to-the-keras-2-api-8a6a5955daac\n",
        "  # autoencoderでは、教師データにラベルを使わないためaccuracyの計算は不要。\n",
        "  autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "  # ------------------------------------------\n",
        "  # 保存した重みを読み込み\n",
        "  autoencoder.load_weights(file_prefix + 'autoencoder.h5')\n",
        "  decoded_imgs = autoencoder.predict(x_test)\n",
        "  # 0-9を表示する\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  label = 0\n",
        "  for i in range(1000):\n",
        "      if label > 10:\n",
        "          break\n",
        "      elif label != y_test[i]:\n",
        "          continue\n",
        "      # オリジナルのテスト画像を表示\n",
        "      plt.imshow(x_test[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      plt.savefig(str(i) + '_x_test_numbers.png')\n",
        "\n",
        "      # 変換された画像を表示\n",
        "      plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      plt.savefig(file_prefix + str(i) + '_decoded_numbers.png')\n",
        "      \n",
        "      label+=1\n",
        "  #  plt.show() #show()するとファイルに保存できないことに注意。\n",
        "  autoencoder.reset_states()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LK23VO2zjflG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 保存した重みのダウンロード\n",
        "from google.colab import files\n",
        "!zip -r h5.zip *.h5\n",
        "!zip -r png.zip *.png\n",
        "!zip -r txt.zip *.txt\n",
        "files.download('h5.zip')\n",
        "files.download('png.zip')\n",
        "files.download('txt.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_j9zZq4yb4Sc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/image/ssim\n",
        "'''\n",
        "This function is based on the standard SSIM implementation from:\n",
        "Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004).\n",
        "Image quality assessment: from error visibility to structural similarity. \n",
        "IEEE transactions on image processing\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}