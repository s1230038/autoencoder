{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoencoderForThesis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1230038/autoencoder/blob/master/AutoencoderForThesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "42k_7hqZp7yx",
        "colab_type": "code",
        "outputId": "efdcbfc6-67a4-4b1f-ad52-9f31bfce890a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "!rm *txt *h5 *png *zip\n",
        "# rm *png *zip *txt"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*txt': No such file or directory\n",
            "rm: cannot remove '*png': No such file or directory\n",
            "rm: cannot remove '*zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d5NaL7in5Jc1",
        "colab_type": "code",
        "outputId": "b0de2ddb-1e37-4a95-b43a-8510e310cd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1049
        }
      },
      "cell_type": "code",
      "source": [
        "# Simple Autoencoder using Other Loss Function\n",
        "# Original: https://elix-tech.github.io/ja/2016/07/17/autoencoder.html\n",
        "# https://colab.research.google.com/drive/1Z_d8APkMUDwXDQIg3OI7E13vH8IZhusM?authuser=1#scrollTo=WmBfOis_mWCH\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import losses\n",
        "from tensorflow.python import debug as tf_debug\n",
        "from itertools import product\n",
        "from google.colab import files\n",
        "from keras import optimizers\n",
        "from keras import constraints as cst\n",
        "\n",
        "# imititing mean_squared_error():\n",
        "# 青イルカ P.57では二乗誤差の総和を使用しているが、これをKerasで実装する場合は平均二乗誤差（mean_squared_error)\n",
        "# をloss に渡す必要がある。なぜなら、Kerasはミニバッチでfit()を計算するからである。青イルカ P.27参照。\n",
        "# 𝒙 ̂_𝑛 :y_pred,  𝒙_𝑛 : y_true, because x_n is training data which means label.\n",
        "def i_divergence1(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean(y_pred * K.log(y_pred / y_true) - y_pred + y_true, axis=-1)\n",
        "\n",
        "def i_divergence2(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean(y_true * K.log(y_true / y_pred) - y_true + y_pred, axis=-1)\n",
        "\n",
        "def is_divergence1(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean( (y_pred / y_true) - K.log(y_pred / y_true) - 1, axis=-1)\n",
        "\n",
        "def is_divergence2(y_true, y_pred):\n",
        "  y_true = K.clip(y_true, K.epsilon(), 1)\n",
        "  y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
        "  return K.mean( (y_true / y_pred) - K.log(y_true / y_pred) - 1, axis=-1)\n",
        "\n",
        "# https://qiita.com/hiroyuki827/items/213146d551a6e2227810\n",
        "def plot_history_loss(np_loss, np_vloss, name):\n",
        "    # Plot the loss in the history\n",
        "    fig, axL = plt.subplots(figsize=(8,6), dpi=500) # グラフの表示準備\n",
        "    axL.plot(np_loss, label=\"loss for training\")\n",
        "    axL.plot(np_vloss, label=\"loss for validation\")\n",
        "    axL.set_title('model loss: ' + name)\n",
        "    axL.set_xlabel('epoch')\n",
        "    axL.set_ylabel('loss')\n",
        "    axL.legend(loc='upper right')\n",
        "    return fig\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "# Download MNIST and standardize, learning\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# we will restrict domain of definition of the input data to the below expression with normalization of the input.\n",
        "x_train = x_train.astype('float32') / 255. # 画像データは0から1の実数値を取るように規格化\n",
        "x_test = x_test.astype('float32') / 255.   # {0,1}の二値ではなく実数値であることに注意\n",
        "# x_trainは (60000, 28, 28) という形をしていますが、784次元の入力になるように (60000, 784) に変形\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "# hyper parameter combination\n",
        "'''\n",
        "lossfs = [losses.mean_squared_error, i_divergence1, i_divergence2, is_divergence1, is_divergence2]\n",
        "acts = [\"relu\", \"sigmoid\"]\n",
        "opzs = [\"SGD\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adam\", \"Adamax\", \"Nadam\"]\n",
        "'''\n",
        "lossfs = [losses.mean_squared_error]\n",
        "acts = [\"relu\", \"sigmoid\"]\n",
        "opzs = [\"SGD\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adam\", \"Adamax\", \"Nadam\"]\n",
        "# ------------------------------------------\n",
        "for loss, dact, optimizer in product(lossfs, acts, opzs):\n",
        "  file_prefix = (loss.__name__ + '_' + dact + '_' + optimizer + '_' )\n",
        "  print(\"start: \" + file_prefix )\n",
        "  encoding_dim = 32\n",
        "  input_img = Input(shape=(784,))\n",
        "  encoded = Dense(encoding_dim, activation='relu', \n",
        "                  kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(input_img) \n",
        "  decoded = Dense(784, activation=dact, kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(encoded)\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded) # https://medium.com/@zhuixiyou/userwarning-update-your-model-call-to-the-keras-2-api-8a6a5955daac\n",
        "  # autoencoderでは、教師データにラベルを使わないためaccuracyの計算は不要。\n",
        "  autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "  # ------------------------------------------\n",
        "  fit = autoencoder.fit(x_train, x_train,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=256,\n",
        "                  shuffle=True,\n",
        "                  verbose=0,\n",
        "                  validation_data=(x_test, x_test))\n",
        "\n",
        "  # lossのCSVファイルの保存\n",
        "  loss_his = fit.history['loss']\n",
        "  vloss_his = fit.history['val_loss']\n",
        "  np_loss = np.array(loss_his)\n",
        "  np_vloss = np.array(vloss_his)\n",
        "  np.savetxt(file_prefix + \"loss_history.txt\",     np_loss,  delimiter=\",\")\n",
        "  np.savetxt(file_prefix + \"val_loss_history.txt\", np_vloss, delimiter=\",\")\n",
        "  \n",
        "  # グラフの保存\n",
        "  fig = plot_history_loss(np_loss, np_vloss, loss.__name__)\n",
        "  fig.savefig(file_prefix + \"loss_history.png\")\n",
        "  plt.close()\n",
        "  \n",
        "  # 学習した重みを保存\n",
        "  autoencoder.save_weights(file_prefix + 'autoencoder.h5')\n",
        "  \n",
        "  autoencoder.reset_states()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start: mean_squared_error_relu_SGD_\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-659992c25c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m                   \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                   validation_data=(x_test, x_test))\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;31m# lossのCSVファイルの保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "grMhsxw10e5o",
        "colab_type": "code",
        "outputId": "880f0636-61c7-4b4a-a774-afcc42ed608d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------\n",
        "for loss, dact, optimizer in product(lossfs, acts, opzs):\n",
        "  file_prefix = (loss.__name__ + '_' + dact + '_' + optimizer + '_' )\n",
        "  print(\"start: \" + file_prefix )\n",
        "  encoding_dim = 32\n",
        "  input_img = Input(shape=(784,))\n",
        "  encoded = Dense(encoding_dim, activation='relu', \n",
        "                  kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(input_img) \n",
        "  decoded = Dense(784, activation=dact, kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(encoded)\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded) # https://medium.com/@zhuixiyou/userwarning-update-your-model-call-to-the-keras-2-api-8a6a5955daac\n",
        "  # autoencoderでは、教師データにラベルを使わないためaccuracyの計算は不要。\n",
        "  autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "  # ------------------------------------------\n",
        "  # 保存した重みを読み込み\n",
        "  autoencoder.load_weights(file_prefix + 'autoencoder.h5')\n",
        "  decoded_imgs = autoencoder.predict(x_test)\n",
        "  # 0-9を表示する\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  label = 0\n",
        "  for i in range(1000):\n",
        "      if label > 10:\n",
        "          break\n",
        "      elif label != y_test[i]:\n",
        "          continue\n",
        "      # オリジナルのテスト画像を表示\n",
        "      ax = plt.subplot(2, 10, label+1)\n",
        "      plt.imshow(x_test[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      # 変換された画像を表示\n",
        "      ax = plt.subplot(2, 10, label+1+10)\n",
        "      plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "      \n",
        "      label+=1\n",
        "  #  plt.show() #show()するとファイルに保存できないことに注意。\n",
        "  plt.savefig(file_prefix + 'numbers.png')\n",
        "  autoencoder.reset_states()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start: mean_squared_error_relu_SGD_\n",
            "start: mean_squared_error_relu_RMSprop_\n",
            "start: mean_squared_error_relu_Adagrad_\n",
            "start: mean_squared_error_relu_Adadelta_\n",
            "start: mean_squared_error_relu_Adam_\n",
            "start: mean_squared_error_relu_Adamax_\n",
            "start: mean_squared_error_relu_Nadam_\n",
            "start: mean_squared_error_sigmoid_SGD_\n",
            "start: mean_squared_error_sigmoid_RMSprop_\n",
            "start: mean_squared_error_sigmoid_Adagrad_\n",
            "start: mean_squared_error_sigmoid_Adadelta_\n",
            "start: mean_squared_error_sigmoid_Adam_\n",
            "start: mean_squared_error_sigmoid_Adamax_\n",
            "start: mean_squared_error_sigmoid_Nadam_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mVwTIp0j2BUE",
        "colab_type": "code",
        "outputId": "7dd2a266-2fa6-4113-b20b-bbfc286f6a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from skimage.measure import compare_ssim, compare_psnr\n",
        "import cv2\n",
        "\n",
        "# ------------------------------------------\n",
        "for loss, dact, optimizer in product(lossfs, acts, opzs):\n",
        "  file_prefix = (loss.__name__ + '_' + dact + '_' + optimizer + '_' )\n",
        "  print(\"start: \" + file_prefix )\n",
        "  encoding_dim = 32\n",
        "  input_img = Input(shape=(784,))\n",
        "  encoded = Dense(encoding_dim, activation='relu', \n",
        "                  kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(input_img) \n",
        "  decoded = Dense(784, activation=dact, kernel_constraint=cst.non_neg(), bias_constraint=cst.non_neg())(encoded)\n",
        "  autoencoder = Model(inputs=input_img, outputs=decoded) # https://medium.com/@zhuixiyou/userwarning-update-your-model-call-to-the-keras-2-api-8a6a5955daac\n",
        "  # autoencoderでは、教師データにラベルを使わないためaccuracyの計算は不要。\n",
        "  autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "  # ------------------------------------------\n",
        "  # 保存した重みを読み込み\n",
        "  autoencoder.load_weights(file_prefix + 'autoencoder.h5')\n",
        "  decoded_imgs = autoencoder.predict(x_test)\n",
        "  # 0-9を表示する\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "  label = 0\n",
        "  for i in range(1000):\n",
        "      if label > 10:\n",
        "          break\n",
        "      elif label != y_test[i]:\n",
        "          continue\n",
        "\n",
        "      xfname = str(label) + '_x_test_numbers.png'\n",
        "      yfname = file_prefix + str(label) + '_decoded_numbers.png'\n",
        "      # オリジナルのテスト画像を表示\n",
        "      plt.imshow(x_test[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      plt.savefig(xfname)\n",
        "\n",
        "      # 変換された画像を表示\n",
        "      plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      plt.savefig(yfname)\n",
        "      \n",
        "      # https://qiita.com/redshoga/items/5e36d784a322c940f38e\n",
        "      # http://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.compare_ssim\n",
        "      img1 = cv2.imread(xfname, cv2.IMREAD_GRAYSCALE)\n",
        "      img2 = cv2.imread(yfname, cv2.IMREAD_GRAYSCALE)\n",
        "      val = compare_ssim(img1, img2)\n",
        "      \n",
        "      sfile = open('ssim.txt' ,mode='a')\n",
        "      sfile.write( xfname + ' - ' + yfname + ': ' + str(val) + '\\n')\n",
        "      sfile.close()\n",
        "      \n",
        "      label+=1\n",
        "  #  plt.show() #show()するとファイルに保存できないことに注意。\n",
        "  autoencoder.reset_states()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start: mean_squared_error_relu_SGD_\n",
            "start: mean_squared_error_relu_RMSprop_\n",
            "start: mean_squared_error_relu_Adagrad_\n",
            "start: mean_squared_error_relu_Adadelta_\n",
            "start: mean_squared_error_relu_Adam_\n",
            "start: mean_squared_error_relu_Adamax_\n",
            "start: mean_squared_error_relu_Nadam_\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  max_open_warning, RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start: mean_squared_error_sigmoid_SGD_\n",
            "start: mean_squared_error_sigmoid_RMSprop_\n",
            "start: mean_squared_error_sigmoid_Adagrad_\n",
            "start: mean_squared_error_sigmoid_Adadelta_\n",
            "start: mean_squared_error_sigmoid_Adam_\n",
            "start: mean_squared_error_sigmoid_Adamax_\n",
            "start: mean_squared_error_sigmoid_Nadam_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LK23VO2zjflG",
        "colab_type": "code",
        "outputId": "da9b6d8d-68fd-4eb3-89fc-2d3df4a8f900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3272
        }
      },
      "cell_type": "code",
      "source": [
        "# 保存した重みのダウンロード\n",
        "from google.colab import files\n",
        "!zip -r h5.zip *.h5\n",
        "!zip -r png.zip *.png\n",
        "!zip -r txt.zip *.txt\n",
        "files.download('h5.zip')\n",
        "files.download('png.zip')\n",
        "files.download('txt.zip')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: mean_squared_error_relu_Adadelta_autoencoder.h5 (deflated 67%)\n",
            "  adding: mean_squared_error_relu_Adagrad_autoencoder.h5 (deflated 71%)\n",
            "  adding: mean_squared_error_relu_Adam_autoencoder.h5 (deflated 85%)\n",
            "  adding: mean_squared_error_relu_Adamax_autoencoder.h5 (deflated 85%)\n",
            "  adding: mean_squared_error_relu_Nadam_autoencoder.h5 (deflated 85%)\n",
            "  adding: mean_squared_error_relu_RMSprop_autoencoder.h5 (deflated 76%)\n",
            "  adding: mean_squared_error_relu_SGD_autoencoder.h5 (deflated 49%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_autoencoder.h5 (deflated 72%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_autoencoder.h5 (deflated 82%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_autoencoder.h5 (deflated 91%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_autoencoder.h5 (deflated 92%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_autoencoder.h5 (deflated 92%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_autoencoder.h5 (deflated 88%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_autoencoder.h5 (deflated 62%)\n",
            "  adding: 0_x_test_numbers.png (deflated 58%)\n",
            "  adding: 1_x_test_numbers.png (deflated 66%)\n",
            "  adding: 2_x_test_numbers.png (deflated 57%)\n",
            "  adding: 3_x_test_numbers.png (deflated 62%)\n",
            "  adding: 4_x_test_numbers.png (deflated 60%)\n",
            "  adding: 5_x_test_numbers.png (deflated 58%)\n",
            "  adding: 6_x_test_numbers.png (deflated 56%)\n",
            "  adding: 7_x_test_numbers.png (deflated 70%)\n",
            "  adding: 8_x_test_numbers.png (deflated 59%)\n",
            "  adding: 9_x_test_numbers.png (deflated 62%)\n",
            "  adding: mean_squared_error_relu_Adadelta_0_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Adadelta_1_decoded_numbers.png (deflated 54%)\n",
            "  adding: mean_squared_error_relu_Adadelta_2_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Adadelta_3_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adadelta_4_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_Adadelta_5_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_Adadelta_6_decoded_numbers.png (deflated 45%)\n",
            "  adding: mean_squared_error_relu_Adadelta_7_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Adadelta_8_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_Adadelta_9_decoded_numbers.png (deflated 50%)\n",
            "  adding: mean_squared_error_relu_Adadelta_numbers.png (deflated 14%)\n",
            "  adding: mean_squared_error_relu_Adagrad_0_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Adagrad_1_decoded_numbers.png (deflated 54%)\n",
            "  adding: mean_squared_error_relu_Adagrad_2_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Adagrad_3_decoded_numbers.png (deflated 50%)\n",
            "  adding: mean_squared_error_relu_Adagrad_4_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_Adagrad_5_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adagrad_6_decoded_numbers.png (deflated 45%)\n",
            "  adding: mean_squared_error_relu_Adagrad_7_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adagrad_8_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Adagrad_9_decoded_numbers.png (deflated 50%)\n",
            "  adding: mean_squared_error_relu_Adagrad_numbers.png (deflated 15%)\n",
            "  adding: mean_squared_error_relu_Adam_0_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Adam_1_decoded_numbers.png (deflated 53%)\n",
            "  adding: mean_squared_error_relu_Adam_2_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Adam_3_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adam_4_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_Adam_5_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_Adam_6_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Adam_7_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adam_8_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_Adam_9_decoded_numbers.png (deflated 52%)\n",
            "  adding: mean_squared_error_relu_Adamax_0_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Adamax_1_decoded_numbers.png (deflated 55%)\n",
            "  adding: mean_squared_error_relu_Adamax_2_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Adamax_3_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adamax_4_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Adamax_5_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adamax_6_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Adamax_7_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Adamax_8_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Adamax_9_decoded_numbers.png (deflated 50%)\n",
            "  adding: mean_squared_error_relu_Adamax_numbers.png (deflated 14%)\n",
            "  adding: mean_squared_error_relu_Adam_numbers.png (deflated 15%)\n",
            "  adding: mean_squared_error_relu_Nadam_0_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Nadam_1_decoded_numbers.png (deflated 52%)\n",
            "  adding: mean_squared_error_relu_Nadam_2_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_Nadam_3_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Nadam_4_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Nadam_5_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Nadam_6_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Nadam_7_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Nadam_8_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_Nadam_9_decoded_numbers.png (deflated 49%)\n",
            "  adding: mean_squared_error_relu_Nadam_numbers.png (deflated 15%)\n",
            "  adding: mean_squared_error_relu_RMSprop_0_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_RMSprop_1_decoded_numbers.png (deflated 52%)\n",
            "  adding: mean_squared_error_relu_RMSprop_2_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_RMSprop_3_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_RMSprop_4_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_RMSprop_5_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_RMSprop_6_decoded_numbers.png (deflated 46%)\n",
            "  adding: mean_squared_error_relu_RMSprop_7_decoded_numbers.png (deflated 47%)\n",
            "  adding: mean_squared_error_relu_RMSprop_8_decoded_numbers.png (deflated 48%)\n",
            "  adding: mean_squared_error_relu_RMSprop_9_decoded_numbers.png (deflated 51%)\n",
            "  adding: mean_squared_error_relu_RMSprop_numbers.png (deflated 14%)\n",
            "  adding: mean_squared_error_relu_SGD_0_decoded_numbers.png (deflated 42%)\n",
            "  adding: mean_squared_error_relu_SGD_1_decoded_numbers.png (deflated 41%)\n",
            "  adding: mean_squared_error_relu_SGD_2_decoded_numbers.png (deflated 43%)\n",
            "  adding: mean_squared_error_relu_SGD_3_decoded_numbers.png (deflated 42%)\n",
            "  adding: mean_squared_error_relu_SGD_4_decoded_numbers.png (deflated 42%)\n",
            "  adding: mean_squared_error_relu_SGD_5_decoded_numbers.png (deflated 42%)\n",
            "  adding: mean_squared_error_relu_SGD_6_decoded_numbers.png (deflated 42%)\n",
            "  adding: mean_squared_error_relu_SGD_7_decoded_numbers.png (deflated 43%)\n",
            "  adding: mean_squared_error_relu_SGD_8_decoded_numbers.png (deflated 42%)\n",
            "  adding: mean_squared_error_relu_SGD_9_decoded_numbers.png (deflated 43%)\n",
            "  adding: mean_squared_error_relu_SGD_numbers.png (deflated 12%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_0_decoded_numbers.png (deflated 79%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_1_decoded_numbers.png (deflated 79%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_2_decoded_numbers.png (deflated 79%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_3_decoded_numbers.png (deflated 79%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_4_decoded_numbers.png (deflated 79%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_5_decoded_numbers.png (deflated 70%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_6_decoded_numbers.png (deflated 44%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_7_decoded_numbers.png (deflated 45%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_8_decoded_numbers.png (deflated 79%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_9_decoded_numbers.png (deflated 79%)\n",
            "  adding: mean_squared_error_sigmoid_Adadelta_numbers.png (deflated 18%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_0_decoded_numbers.png (deflated 59%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_1_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_2_decoded_numbers.png (deflated 65%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_3_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_4_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_5_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_6_decoded_numbers.png (deflated 63%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_7_decoded_numbers.png (deflated 65%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_8_decoded_numbers.png (deflated 60%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_9_decoded_numbers.png (deflated 62%)\n",
            "  adding: mean_squared_error_sigmoid_Adagrad_numbers.png (deflated 18%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_0_decoded_numbers.png (deflated 59%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_1_decoded_numbers.png (deflated 65%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_2_decoded_numbers.png (deflated 62%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_3_decoded_numbers.png (deflated 62%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_4_decoded_numbers.png (deflated 62%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_5_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_6_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_7_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_8_decoded_numbers.png (deflated 60%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_9_decoded_numbers.png (deflated 63%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_0_decoded_numbers.png (deflated 58%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_1_decoded_numbers.png (deflated 63%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_2_decoded_numbers.png (deflated 63%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_3_decoded_numbers.png (deflated 62%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_4_decoded_numbers.png (deflated 59%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_5_decoded_numbers.png (deflated 58%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_6_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_7_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_8_decoded_numbers.png (deflated 59%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_9_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Adamax_numbers.png (deflated 18%)\n",
            "  adding: mean_squared_error_sigmoid_Adam_numbers.png (deflated 18%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_0_decoded_numbers.png (deflated 58%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_1_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_2_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_3_decoded_numbers.png (deflated 63%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_4_decoded_numbers.png (deflated 59%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_5_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_6_decoded_numbers.png (deflated 68%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_7_decoded_numbers.png (deflated 66%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_8_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_9_decoded_numbers.png (deflated 65%)\n",
            "  adding: mean_squared_error_sigmoid_Nadam_numbers.png (deflated 18%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_0_decoded_numbers.png (deflated 58%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_1_decoded_numbers.png (deflated 65%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_2_decoded_numbers.png (deflated 60%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_3_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_4_decoded_numbers.png (deflated 59%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_5_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_6_decoded_numbers.png (deflated 64%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_7_decoded_numbers.png (deflated 67%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_8_decoded_numbers.png (deflated 58%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_9_decoded_numbers.png (deflated 61%)\n",
            "  adding: mean_squared_error_sigmoid_RMSprop_numbers.png (deflated 18%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_0_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_1_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_2_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_3_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_4_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_5_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_6_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_7_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_8_decoded_numbers.png (deflated 38%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_9_decoded_numbers.png (deflated 39%)\n",
            "  adding: mean_squared_error_sigmoid_SGD_numbers.png (deflated 11%)\n",
            "  adding: ssim.txt (deflated 84%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}